---
title: 'Futarchy: Governance for AI Development Using Prediction Markets and Community Feedback'
date: 2025-04-06
authors:
  - christopher
---

## 1. Introduction

AI development today faces a dual challenge: models are growing ever more complex, yet aligning them with human needs requires extensive oversight and feedback. Fission’s DeSAi framework (Decentralized Science + AI) addresses this by combining advanced model optimization techniques with large-scale human feedback loops (e.g., Reinforcement Learning from Human Feedback, RLHF) and community-driven governance. The central question, however, is how to incentivize and coordinate these decentralized feedback processes effectively.

Fission’s answer is Futarchy—a governance model in which communities do not simply vote on proposals, but instead **bet** on which proposals will best fulfill a shared success metric. By rewarding accurate predictions and penalizing mistaken ones, Futarchy taps into collective expertise to guide strategic decisions. This research report explores how Futarchy can be applied to optimize AI development and deployment within the DeSAi paradigm. Specifically, it will:

1. **Define Futarchy and its Core Mechanics**
   Explain how prediction markets function in an on-chain governance context.
2. **Apply Futarchy to AI Optimization**
   Examine how conditional markets can shape AI model improvements through community feedback and economic incentives.
3. **Discuss Technical Implementation**
   Detail the use of decentralized oracles, time-weighted average price (TWAP) mechanisms, and other features needed for reliable performance tracking.
4. **Outline a Hybrid Rollout Strategy**
   Propose steps for transitioning from off-chain or advisory market trials to fully on-chain Futarchy, ensuring stakeholder trust and participation.
5. **Review Key Case Studies**
   Highlight real-world experiments—such as [Augur](https://arxiv.org/pdf/1501.01042), GnosisDAO, and more recent initiatives—that demonstrate both the potential and challenges of futarchic governance.
6. **Identify Risks and Mitigations**
   Analyze common pitfalls—market manipulation, low liquidity, poorly chosen metrics—and discuss safeguard techniques.
7. **Present an End-to-End Futarchy Flow**
   Illustrate how proposals move from initial community submission to on-chain market assessment, model implementation, and verified outcomes.
8. **Conclude with a Vision for AI Governance**
   Summarize how Futarchy can become a transformative model for AI governance and offer insights on practical adoption.

Throughout, we maintain a focus on aligning AI development with community values—“**vote on values, but bet on beliefs**,” in the spirit of Futarchy’s guiding principle. By leveraging prediction markets and decentralized participation, Fission’s approach seeks to ground each model update and research decision in real data and collective expertise, rather than top-down judgment or speculation. This synergy can lead to a more transparent, accountable, and ultimately more effective path forward for AI.

<!-- truncate -->

---

## 2. What is Futarchy?

**Futarchy** is a governance model proposed by economist Robin Hanson in which _“we would vote on values, but bet on beliefs.”_ In other words, the community agrees on a set of values or goals (e.g. a metric of success), and then uses [prediction markets to decide which policies will best achieve those goals](https://mason.gmu.edu/~rhanson/futarchy.html). In a Futarchy system, decision-making typically unfolds in two phases:

### **2-1. Define the Success Metric**

The community or its elected leaders formally define a clear, measurable metric that represents the desired outcome. In a national context this might be a measure of welfare; in an AI context it could be _model accuracy_, _user satisfaction score_, _safety compliance rate_, etc. This metric is essentially the **value** everyone agrees to pursue. Defining the right metric is crucial, as it becomes the yardstick for policy success.

### **2-2. Bet on Proposals**

For any proposed action or policy, a prediction market is created to forecast the outcome of that action on the chosen metric. Typically this involves conditional markets: one market represents the world where the proposal is implemented, and another represents the world where it is not implemented. Participants buy and sell tokens in these markets, effectively betting on the future value of the metric under each scenario. The market prices (or odds) indicate the collective belief about the metric’s level if the proposal passes vs. if it fails. Once the market has run for some time, if the “implement” price is higher than the “don’t implement” price, it means traders expect the proposal to improve the metric – and that proposal is then approved for execution. If the market signals the opposite, the proposal is rejected. After execution (for approved proposals), the metric is later measured in reality and those who bet correctly are rewarded, while incorrect bets lose their stake.

### **2-3. On-chain decision-making**

In a blockchain setting, Futarchy can be implemented via smart contracts. A smart contract can automatically create the conditional markets for a proposal and even enforce the outcome. For example, an AI governance contract might say: _“If the market predicts higher accuracy with Model Update A, then after a week of trading, automatically deploy Update A. Otherwise, keep the status quo.”_ This was the [approach taken by GnosisDAO](https://medium.com/gnosis-pm/scaling-prediction-markets-via-pooled-liquidity-market-creation-via-oracles-bbf0e2cbc44f), which integrated prediction markets into its governance so that any protocol change had associated markets guiding the vote. On-chain Futarchy uses **oracles** to resolve outcomes – once the success metric is observed (e.g. the model’s accuracy after deployment), the oracle feeds this data into the contracts to determine payouts for bets and confirm whether the metric rose or fell. The entire process is transparent: every bet and price movement is on record, and the final decision emerges from the market data rather than a back-room discussion. This aligns with the ethos of decentralized governance by **vesting decision-making authority in “the market’s” collective intelligence** rather than a few individuals.

To illustrate Futarchy in simple terms, imagine a DAO that governs an AI research fund. The DAO’s value to maximize might be the _accuracy of a certain ML model on a benchmark dataset_. Someone proposes to add a new dataset for training to improve accuracy. Instead of just voting yes/no, the DAO spins up two markets: one token that pays out (say) $1 _times_ the model’s accuracy if the dataset **is added**, and another token that pays out $1 _times_ the accuracy if the dataset **is not added**. If traders believe adding the data will push accuracy from, say, 85 to 90, they will bid up the price of the “added” token (since its expected payoff is higher). If the status quo is expected to perform better, the “not-added” token price will rise. These token prices essentially become forecasts of the model’s performance under each scenario. The governance rule could be: _if the price-implied accuracy with the new dataset is at least, e.g., 2 points higher than without it, automatically approve the addition._ By doing this, Futarchy **“transforms financial speculation into a community filter”** for decisions – those with knowledge and confidence back their beliefs with stakes, and the aggregate result guides the AI’s evolution.

Prediction markets in Futarchy leverage a well-demonstrated capability: **efficient information aggregation**. They harness the “wisdom of the crowd,” weighted by how strongly that crowd believes in its information (via money at stake). For complex decisions like AI policies, this has an advantage over traditional votes: voters might not understand the technical details, but traders who do understand (or who research deeply) will drive the market prices. In essence, Futarchy separates _values_ (which everyone can have a say in – e.g., _we want the AI to be safe and accurate_) from _beliefs about how to achieve those values_ (which are best informed by data and expertise). The community still sets the goals democratically, but prediction markets determine the best means to those goals. On-chain, this process becomes a form of autonomous governance: if designed correctly, a Futarchy-based DAO could run continuously, updating its policies or AI model whenever the market predicts an improvement, with minimal human bureaucracy. All that’s needed is a reliable way to measure outcomes and reward the predictors – topics we’ll cover in later sections.

---

## 3. Applying Futarchy to AI Optimization

How can Futarchy specifically guide AI development and optimization? In the DeSAi context, we have a continual loop of human feedback (e.g. RLHF, user evaluations) and model updates. Futarchy can be layered on top of this loop as a decision mechanism to **select and prioritize model improvements** that yield genuine performance gains. Several aspects are worth examining:

### **3-1. Community-Sourced Feedback Validation**

Modern AI alignment techniques like RLHF rely on human annotators or users providing feedback on the AI’s outputs. This can generate a wealth of proposals for improving the model – for instance, _“fine-tune the model on domain X where users report poor results”_ or _“adjust the reward function to penalize toxic language”_. Futarchy offers a way to validate such community-driven ideas by testing their predicted impact on agreed metrics. Essentially, each proposal derived from human feedback can be put to a prediction market that asks, _“If we implement this change, will the model’s performance metric improve?”_ The community of token holders (which could include developers, users, domain experts) then evaluates the proposal through their betting. Because people are staking value on the outcome, the process incentivizes rigorous validation of feedback: only feedback that is expected to translate into measurable improvement will attract positive bets. This helps filter out well-intended but low-impact suggestions. It also closes the loop with the crowd – the same users giving feedback can **earn rewards if their insights truly lead to improvements**, by betting on the proposals they think will work. In Fission’s vision, Futarchy ensures **“outcome-focused upgrades”**: collective feedback is funneled into proposals, and the market’s **“consensus directs energy toward meaningful improvements”**. Meanwhile, if someone tries to game the feedback (e.g., artificially inflate a metric through spam), knowledgeable participants can bet against that and expose it, providing **resilience against gaming**. This dynamic validation means the community not only supplies feedback but also actively curates which feedback to act on, using economic signals.

### **3-2. Market-Based Filtering of Model Updates**

AI model development often involves continuous iteration – dozens of experiments and hyperparameter tweaks are possible, but only some will yield a better model. Traditionally, researchers run A/B tests or offline evaluations to choose the best model. In a decentralized setting, one could instead open the process to a prediction market. For each candidate model update (a new training run, a new architecture, etc.), create a market forecasting the model’s **performance metric** (accuracy, F1 score, etc.) if that update is adopted. The current model’s performance provides a baseline in the “do nothing” market. Participants then trade on which version will be better. This effectively outsources the model selection to the community’s collective intelligence. Ideas that are hype or unsubstantiated will likely see skepticism (low prices) from experienced predictors and get filtered out. By contrast, an update that, say, fixes a known bug or incorporates a better dataset might see strong market support, signalling to developers and governance that it’s worth implementing. In this way, Futarchy **“acts as a filter for authenticity, ensuring speculation aligns with actual model improvements.”** The moment a proposal is made, anyone suspecting it to be _“hollow claims”_ can short it (bet against) and profit when it fails, whereas those who see a _“solid idea”_ will go long and drive it forward. Over time, this market-based filtering can outperform any single committee or team in prioritizing updates, because it taps a broad range of knowledge – from core developers to end-users who might notice corner cases. It’s essentially a meritocratic swarm intelligence: proposals compete for funding/support in the market, and only the fittest (in terms of predicted metric gains) survive. Fission’s DeSAi approach highlights that this mechanism channels the often speculative energy of crypto markets into productive use: _“By centering resources on verifiable performance instead of promises, Futarchy transforms financial speculation into a community filter.”_. In other words, _token holders become the reviewers and testers_ for each AI change, and they have skin in the game to choose correctly. This could greatly accelerate AI improvement, as promising ideas get quickly identified and funded, whereas weak ideas are swiftly abandoned due to lack of market support.

### **3-3. Rewarding Accurate Predictions (Performance Incentives)**

A core feature of Futarchy is that those who predict correctly are financially rewarded. In guiding AI optimization, this creates a powerful incentive alignment: community members who truly understand what will improve the model (or who conduct thorough experiments) stand to gain, whereas guesses or unfounded opinions lose money. For example, suppose a researcher in the community believes that adding a certain data augmentation will boost the model’s accuracy. In a Futarchy system, they could propose that change and also bet on its success. If they’re right (the model improves and the market correctly foresaw it), the value of their shares goes up and they earn a profit when the outcome is verified. Conversely, if someone bets on an improvement that fails to materialize, they lose their stake – effectively **penalizing inaccurate predictions**. This creates a direct feedback loop for accountability. Over multiple iterations, the community members who consistently make good calls (perhaps experienced ML engineers or astute crowd analysts) will accumulate more capital (and potentially influence), whereas those who bet on hype or ignore empirical evidence will lose capital. In this manner, Futarchy tends to **elevate the credible voices** in the decision process by virtue of market success. The prospect of profit motivates participants to seek out data, run experiments, or otherwise inform themselves before betting – behavior that a simple vote might not inspire. Moreover, by tying rewards to _objective metrics_, it minimizes bias: you are rewarded for being _right_, not for being popular. In the AI context, those who deeply understand the model or domain can earn from their expertise. For instance, a domain expert in medicine might know that a certain tweak will improve a medical chatbot’s usefulness; through Futarchy they can back that insight financially and reap rewards when the chatbot’s user satisfaction indeed goes up. This mechanism also crowdsources the evaluation effort – people will try to poke holes in proposals (since if they find a flaw, they can bet against it and profit). As Fission noted, savvy participants collectively enforce **“integrity”**: proposers must _“deliver real results if they hope to gain from the predictive markets.”_ All of this creates a culture of evidence-based progress. It’s akin to a continual Kaggle competition or a quant trading floor, where good ideas are lucratively rewarded. Importantly, even those not proposing changes can contribute: for example, a user who notices the AI performs poorly on a type of query can bet that a proposal addressing that issue will succeed, thus lending support (liquidity and signal) to that proposal. Overall, by **rewarding accurate predictions and penalizing incorrect ones**, Futarchy _aligns the incentives_ of the AI community with the goal of improving the model’s true performance. Instead of political battles or sunk-cost fallacies, decisions boil down to: did it work or not? – and those who bet according to truth win out.

To make this concrete, consider a scenario: Our AI model’s key metric is user satisfaction, gathered via surveys. Two competing proposals emerge from the community for increasing user satisfaction: (A) fine-tune the model on a new polite-dialogue dataset, (B) implement a stricter moderation filter to avoid offensive outputs. The Futarchy approach would set up markets for each proposal (or a combined market with outcomes: “A only”, “B only”, “Both A and B”, “Neither”).

Participants research and recall examples: maybe they find that politeness (A) greatly improves user happiness, whereas the current model rarely offends so (B) might not move the needle. They bet accordingly – say, heavy on A being beneficial. If the market consensus is that A would raise satisfaction more than status quo, but B wouldn’t add much on top, then action (A) will be approved. After deployment, suppose user satisfaction indeed jumps up by the amount predicted. The oracle reports the new satisfaction score on-chain, markets settle, and those who bet on A (and perhaps against B) receive payouts proportional to their stake and the accuracy of the forecast. The DAO’s treasury might even grant a bonus reward to the proposer of A. The end result: the model improved on a real metric, the community members who foresaw the improvement were rewarded, and those funds could have come from those who bet on a wrong outcome (so no net loss to the treasury, it’s redistribution among predictors). This virtuous cycle can repeat for each iteration, driving a **“sustainable evolution”** where stakeholders continuously reinvest in the model’s growth. Participants who believe strongly in the AI’s long-term potential might hold on to their rewards or reinvest them in future proposals, reinforcing a community-led growth engine. In summary, Futarchy doesn’t just crowdsource ideas – it **crowdsources judgment**, with money as the signal. By doing so, it guides AI development along a path that is both **community-driven and outcome-verified**, fulfilling the promise that decentralized input (DeSci) plus market discipline can produce better results than either alone.

---

## 4. Technical Implementation: Oracles and TWAP for Verifiable Performance Tracking

Implementing Futarchy for AI governance on-chain requires a robust technical setup to ensure that decisions are made on true data and are resistant to manipulation. Two key components in this setup are **decentralized oracles** (to feed real-world performance metrics into the blockchain) and **time-weighted average price (TWAP)** mechanisms (to determine market consensus fairly). We discuss these below, along with how they enable verifiable tracking of AI performance.

### **4-1. Decentralized Oracles for AI Metrics**

In a futarchic AI governance system, once a proposal is executed (e.g., a new model version is deployed), we need to measure the outcome _on-chain_ to reward bettors. This is the job of an oracle. A decentralized oracle is a system (often a set of smart contracts plus off-chain data providers) that delivers data from the outside world to the blockchain in a trustworthy manner. For our use case, the oracle’s payload might be: _“Model v2’s accuracy = 91.3% on the evaluation set”_ or _“User satisfaction score = 4.5 out of 5 after one week of deployment.”_ Designing this oracle involves several steps to ensure verifiability:

### **4-2. Predefine Metrics and Data Sources**

The governance process must specify _how_ the metric will be measured. For example, if accuracy is the metric, the DAO might fix a particular test dataset and evaluation script ahead of time. If user satisfaction is the metric, it might be an average of on-chain user ratings collected via a dApp. By fixing the procedure, we remove ambiguity. This specification is written into the proposal’s smart contract so that everyone betting knows exactly what outcome will be reported.

### **4-3. Data Collection and Reporting**

Once the proposal is executed, data needs to be collected. In a decentralized spirit, multiple independent parties could run the evaluation. For instance, three trusted AI auditors (which could be universities or reputable firms) might each run the new model on the test set and submit the accuracy. Ideally, their results should match; if not, a dispute resolution mechanism (like a majority vote or a follow-up check by a smart contract if the model and data are available on-chain) can be used. Technologies like secure multiparty computation or zero-knowledge proofs can also be employed to prove a certain accuracy was achieved without revealing test answers (to prevent cheating by overfitting). Simpler, the test data could be made public only after model training is done (commit-reveal style), so proposers can’t tune to it specifically.

### **4-4. On-Chain Verification**

The oracle smart contract takes the reported data (say the three accuracy values). If they are within an allowable range of each other, it might take an average or median and treat that as the official result. This result is then posted on-chain in the format the futarchy market expects (e.g., the value of the metric or a boolean “met target or not”). Because the oracle is decentralized (multiple reporters), it’s harder for a single bad actor to falsify the outcome. Additionally, [**Augur-like mechanisms**](https://blogs.cornell.edu/info2040/2018/11/12/augur-decentralized-prediction-market/#:~:text=betters,their%20share%20of%20the%20winnings) can be used: Augur’s REP system showed that a token-weighted reporter pool can reliably report truths under economic incentive. In our case, one could imagine a pool of “AI outcome reporters” who stake a token and are rewarded for aligning with the consensus outcome (which should be the true outcome) – if someone submits a false metric and others dispute it, the liar loses stake. Essentially, the oracle itself could be run as a mini prediction market on “what was the outcome?”, encouraging honest reporting. This is likely overkill if metrics are straightforward, but useful if there’s subjectivity.

### **4-5. Automation and Smart Contract Action**

Finally, the oracle passes the verified metric to the futarchy governance contract. The contract then automatically determines winners of the bets. If the governance is fully on-chain, it also triggers the decision outcome (though in AI’s case, implementing a model update might be an off-chain action done by developers; however, the governance contract could at least release funds or update a registry to signal which model is “active”). All of this happens without manual intervention, creating a **trust-minimized loop** from proposal to implementation to evaluation.

For example, consider a decentralized oracle for user satisfaction: a miniApp could be deployed to users prompting them to rate the AI’s answers for a week. Those ratings (each possibly signed by the user’s key) are aggregated by a smart contract which computes the average rating. To ensure integrity, perhaps only users who had authenticated identities or staked a small deposit could rate (to prevent bots), and the raw data could be made available for the community to audit (ensuring no tampering). After one week, the contract calculates the **time-average of satisfaction** and posts that number on the chain as the official metric. The futarchy contract reads it and settles bets accordingly. In summary, decentralized oracles are the bridge between the off-chain reality of AI performance and the on-chain prediction markets. They must be designed to be **tamper-resistant and transparent** because if the oracle can be corrupted, so can the Futarchy outcome. Techniques from the broader oracle field (e.g., using multiple data sources, economic collateral for truth-telling, cryptographic verification) are employed to maintain trust in the performance data.

### **4-6. TWAP for Fair Outcome Prices**

A major vulnerability in any prediction market (especially one that directly triggers decisions) is the risk of price manipulation at the moment of decision. In a blockchain context, imagine if the decision is made by looking at the market price at block X – a whale trader could buy a large amount in market “A (proposal passes)” at block X, artificially boosting that price, causing the proposal to pass, and then perhaps benefit from some external effect of that decision. To guard against such exploits, Futarchy implementations use **TWAP (time-weighted average price)** or similar mechanisms to determine the market’s consensus price over a period, rather than at a single instant. This approach has been pioneered in DeFi (for example, decentralized exchanges use TWAP oracles to prevent price manipulation in lending protocols), and it’s directly applicable to futarchic governance.

In practice, a **TWAP oracle** contract will continuously track the prices of the conditional markets throughout the trading period of a proposal. For instance, if a proposal’s markets run for one week, the TWAP might sample the price every block or every hour, accumulating these values into a cumulative index. At the end of the week, the average price is computed by dividing by the number of samples (possibly weighted by time intervals). **The decision is then based on these average prices**, not just the final tick. In other words, the system doesn’t care what the price is exactly at closing time; it cares about the prevailing price trend over the entire period.

Why is this effective? Let’s consider a concrete example: Suppose over 7 days, a proposal’s “pass” market token mostly traded around $0.80 (indicating fairly high confidence that passing the proposal will improve the metric), and the “fail” market token traded around $0.75 (their prices might not sum to 1 if the metric isn’t binary, but we interpret them comparatively). If an attacker waits until the very end and pumps “pass” to $1.00 in the last few minutes, the TWAP might only move a little. If the price was $0.80 for 7 days and $1.00 for 10 minutes, the time-weighted average might come out to something like $0.801—barely changed. Thus, the outcome (which market had the higher TWAP) remains “pass” by roughly the same margin, rather than being skewed by the short-term price spike. Conversely, a brief dump to drive the price down would have a similarly small effect on the overall average. In essence, TWAP requires sustained price distortion **over a long duration** to significantly alter the outcome, making manipulation much more difficult and expensive.

Additionally, honest participants have time to react. If someone tries to suppress a market unfairly, arbitrage traders will notice the mispricing and push it back toward a fair value. By spreading the impact of price data across a longer window, TWAP helps capture the “collective wisdom” more accurately, rather than letting a single moment decide the result.

To implement TWAP on-chain, one common approach is to use an [**AMM (automated market maker)**](https://docs.uniswap.org/contracts/v2/concepts/core-concepts/oracles) that keeps a cumulative price value in each block. Other implementations might track price updates periodically in an order-book structure. At proposal finalization, the futarchy contract queries the TWAP oracle. If, for example, the “pass” market’s average price is higher than the “fail” market’s by a sufficient margin, the proposal is deemed successful. Only after that does the contract allow settlement of the losing side’s positions, while winners realize their gains.

### **4-7. Lagging or Resilient TWAP**

One nuance – in some systems (especially on certain blockchains), even a TWAP can be manipulated by validators if they control time of execution. MetaDAO’s documentation points out that a validator could potentially push through a few blocks of extreme prices if they have control, even in a TWAP. To mitigate this, they implemented a _“lagging price TWAP”_ that limits how fast the reported price can change, further smoothing out anomalies. The general idea is to make the oracle itself a bit inertial – it can’t jump to an absurd new price reading instantly; it will calibrate over several blocks. This makes it practically impossible for a short-lived manipulation to tip the scales. Such techniques, though technical, significantly bolster the **integrity of the futarchy decision process**.

In summary, using a TWAP mechanism ensures that the **“collective wisdom”** over the entire decision window is what determines the outcome, rather than a potential last-moment vote-buying or market raid. It’s about capturing the **robust consensus** rather than a snapshot. Any implementation of on-chain futarchy for AI should incorporate this concept, given how directly decisions can affect incentives. For instance, if a proposal’s approval could influence token price or some external payoff, stakeholders might try to swing it – TWAP protects against that. Additionally, TWAP data can be made public throughout the vote, increasing trust: observers can see the rolling average prices and feel confident there won’t be a sudden flip that wasn’t reflective of the week-long sentiment. As the Helius devs noted when analyzing futarchy, _“The use of TWAPs and conditional tokens helps ensure that a stable and representative market consensus informs decision-making.”_ This stability is crucial when applying futarchy to something like AI governance, where we want decisions to be correct and not just quick. By combining TWAP with decentralized oracles, we get a system where each AI governance decision is based on **sustained market predictions of verifiable outcomes** – arguably one of the most rigorous decision criteria one can ask for.

### **4-8. Verifiable Performance Tracking**

Ensuring that performance improvements are _verifiable_ means that we rely on objective, hard data rather than subjective judgment for outcomes. We’ve touched on oracle design for this, but it’s worth emphasizing how Futarchy can enforce verifiability. In a traditional AI project, a team might say “we feel the model is better after this change” – perhaps based on anecdotes or preliminary tests. In a futarchic system, _feeling_ is not enough; the improvement must manifest in the agreed metric or the market will punish the decision. This creates pressure to track and quantify performance carefully. Over time, the DAO might build up a suite of **on-chain metrics dashboards**. For example, it could maintain an on-chain log of the model’s weekly accuracy, fairness scores, uptime, etc. Each of these could feed into the prediction markets (some might even be directly speculated on for forecasting long-term trends). Tools like **time-series oracles** can record these metrics with historical context, enabling, say, a moving average or comparison against baseline.

An interesting implementation detail is if the AI system is itself accessible on-chain (or via a decentralized network), one could run _continuous evaluation_. Consider a scenario: the futarchy contract doesn’t just pick one moment to measure accuracy; it could, in theory, measure the accuracy of the deployed model on a rolling basis (e.g., every hour on fresh queries) and reward traders based on a **time-averaged outcome** as well. This would reduce variance and discourage trying to “game” the evaluation with one-off tricks. In DeFi oracles, this is analogous to taking a TWAP of the outcome metric itself. In AI, though, metrics usually need static test sets to be comparable over proposals, so more straightforward is doing one measurement per proposal. Still, the practice of tracking multiple metrics (accuracy, robustness, bias) via oracles, and possibly requiring a proposal to not hurt any of them, could be instituted. Futarchy can handle **multi-metric decisions** by having conditional markets on composite outcomes (though it becomes complex). Alternatively, separate futarchy votes could be held for different objectives (one for accuracy, one for safety) and a proposal passes only if it wins in all relevant markets.

Technically, decentralized oracle networks like **Chainlink** are starting to support more generalized data feeds (beyond just token prices). For a DeSAi DAO, one could register a **Chainlink External Adapter** that, for instance, pulls from an IPFS or Arweave file containing the evaluation results, provided by a consortium of trusted evaluators. Those evaluators might sign the results, and the adapter verifies signatures and pushes the data on-chain. If absolute decentralization is needed, the DAO could use a prediction market _for the oracle itself_ (like Augur or UMA’s Data Verification Mechanism) to settle contentious outcomes. This might be overkill for AI metrics, but it’s an option for maximal trustlessness. The key is that every number the futarchy uses to decide or reward is anchored in something independently checkable.

In summary, the technical backbone of futarchy-driven AI governance consists of **smart contracts for conditional markets**, **oracle mechanisms for outcome data**, and **TWAP logic for fair pricing**. Together, these ensure that decisions are made based on reliable forecasts and that those forecasts are settled against ground truth in a way that’s difficult to cheat. [As MetaDAO’s experience shows](https://www.helius.dev/blog/futarchy-and-governance-prediction-markets-meet-daos-on-solana), implementing these components is feasible: they engineered a full stack where DAOs on Solana could launch futarchic votes that automatically execute code changes when the TWAP indicates a win, with everything from price feeds to decision enforcement handled by programs. The AI use-case adds some complexity in gathering outcomes (since metrics might not be on-chain by default), but with a mix of cryptographic commitments and decentralized reporting, the performance of AI models can indeed be **quantified and fed into on-chain markets**. This verifiability is at the heart of why Futarchy is exciting: it replaces vague promises with bets that must be cashed out in real data. [As one Optimism futurist put it, _“when decision-makers are held accountable for decisions (i.e., rewarded for accurate predictions and penalized for inaccurate ones), it incentivizes thoughtful, rather than biased, decisions.”_](https://gov.optimism.io/t/experimenting-with-futarchy-for-optimism-grant-allocation-decisions/9678) By embedding that principle in the smart contracts, we create an AI governance system that is both nimble and principled – nimble in using live market data, principled in requiring proof of improvements.

---

## 5. **Hybrid Rollout Strategy: From Off-Chain Trials to On-Chain Futarchy**

While Futarchy holds promise, it is also a sophisticated mechanism that communities may need time to adapt to. A **hybrid rollout strategy** can help transition from traditional or off-chain decision processes to fully on-chain futarchic governance. In practical terms, this means starting with futarchy-like practices in a controlled environment, then gradually increasing the stakes and moving on-chain once confidence grows. Here’s how such a strategy can be executed:

### **5-1. Trial Phase**

Before entrusting critical AI governance to smart contracts, the community can simulate futarchy in a low-risk setting. This might involve running prediction markets on a centralized platform or even using play money (test tokens) to predict outcomes of model changes. The idea is to let the community practice the _betting on beliefs_ part without the immediate consequences. For example, a Discord or web forum could host **forecasting contests** for proposed AI updates. Participants might be given a budget of points or _PLAY tokens_ (with no real monetary value) to bet on different proposals. The outcome is later measured and winners are recognized or given reputation points. This approach was adopted by the Optimism Collective in 2025: they launched a _Futarchy Grants Contest_ where forecasters used test “PLAY” tokens (allocated based on their reputation in the community) to predict which grant projects would most increase Optimism’s usage. Top forecasters then earned actual OP token rewards. Notably, during this contest the decisions were not actually made by the market – the market was run in parallel to see if it could outperform the normal grant committee, thereby **experimenting with futarchy in a sandbox**. Such a contest is very much in the spirit of _Catarchy_: it’s an isolated trial of futarchy principles. In our AI context, we could do similarly – perhaps running a mock futarchy on past AI model changes to see how well the community would have predicted outcomes, or on minor non-critical decisions to build experience. This phase allows identification of issues (e.g., did people understand the metric? was there enough participation? did anyone try to game it?) without risking project governance. It also helps to **educate and on-board** the community: participants learn by doing, and observers start trusting the concept as they see markets correctly predict some outcomes.

### **5-2. Gradual On-Chain Integration (Hybrid Governance)**

Once the community is familiar with futarchy dynamics and the oracle infrastructure is in place, the next step is to introduce futarchy into the actual governance process, but in a **gradual, “guardrails-on” manner**. One common approach is to start with **advisory** **prediction markets** alongside existing voting mechanisms. For instance, a DAO can continue to have token-holder voting or a multisig team making final calls, but they create prediction markets for each proposal and publicize the results.

GnosisDAO’s initial implementation was along these lines: any Gnosis Improvement Proposal (GIP) that came up for a vote had an associated prediction market where people could bet on the impact to Gnosis (the platform/token). The outcome of that market was visible to voters as a signal of what “the market thinks” about the proposal’s value. However, voters weren’t strictly bound to follow it – at least initially. In practice, if the market strongly favored a proposal yet it got voted down (or vice versa), it would indicate a discrepancy that could be discussed. Over time, the intent was to build trust in the market signal such that eventually the vote could be replaced by the market entirely.

Similarly, the DAO might choose certain domains for futarchy first. For example, “We will use futarchy to decide which research project to fund (advisory for the first 3 rounds, then binding), but we won’t use it yet for core security updates.” This **segmentation by decision type** allows testing futarchy where stakes are lower or more quantifiable, while keeping human control in sensitive areas until proven. The hybrid period can also involve setting **thresholds**: the DAO could adopt a rule like, “If the prediction market odds for a proposal are above 80% likely to improve the metric, the multisig will approve it; if below 50%, we reject it; in between, we go to a normal vote.” This sort of rule uses the market as a filter/gate, but still retains a traditional process for borderline cases. It’s a cautious way to blend old and new governance. Throughout this phase, it’s important to evaluate how well the markets are functioning – e.g., is liquidity improving as people gain confidence? Are the oracle measurements reliable? Are there instances where the community felt the market was “wrong,” and how do we address that?

### **5-3. Progressively Increasing Stakes (All-In On-Chain)**

After successful trials and hybrid usage, the final step is to transition to fully on-chain, autonomous futarchy for most (or all) governance decisions. By now, the community should have the expertise and safeguards needed. Going “all-in” could mean that the DAO’s smart contracts automatically execute certain proposals based on the prediction market outcome, without a manual vote. For example, the DAO could instantiate a **Futarchy module** (some projects like DAOstack and GNOSIS had early versions of this) which takes as input a proposal description and target metric, spins up conditional token markets, and after a set period, resolves and enacts the decision. At this stage, traditional governance mechanisms step back. They may still exist in a fail-safe capacity (e.g., an emergency brake multisig if something egregious happens, like a bug in the market contract), but they are no longer used in day-to-day operations. The community now “votes” entirely by trading.

Notably, some communities remain partially hybrid. For instance, Gnosis decided not to fully eliminate token voting even after experimenting with futarchy. On the other hand, some DAOs on Solana have fully committed to futarchy, foregoing standard governance votes. The choice depends on earlier successes and overall community comfort. It may also unfold gradually within futarchy itself: at first, the DAO might still require a confirming vote (expected to rubber-stamp if the market signal is clear), eventually removing the vote if it consistently aligns with the market anyway. Throughout this transition, **communication and transparency** are crucial. Members should see empirical evidence that futarchy works for their use case (e.g., “The markets accurately predicted 9 out of 10 model updates”), building trust that it’s not just theory.

### **5-4. Ongoing practice**

Even after futarchy is established, maintaining some off-chain or testing component can be valuable for **continuous calibration**. The community might run simulation rounds or parallel futarchy on historical decisions to check if the markets are well-calibrated (e.g., do 70% events happen ~70% of the time?). It also helps with **community onboarding**: new members can practice in a demo futarchy market with fake stakes before jumping into the real one.

Real-world phased rollouts show mixed but instructive results. GnosisDAO’s experiment in late 2020 underscored the importance of starting small. Attempting futarchy on a "**billion-dollar treasury"** immediately led to challenges like low engagement and potential arbitrage by a few traders. The lesson is to keep initial trials inexpensive and educational. On the other hand, not progressing beyond a mere “advisory” stage can limit futarchy’s impact if participants don’t take the markets seriously. Striking a balance is key. **Optimism** (an Ethereum L2) also explored a hybrid approach, running a futarchy contest in parallel with its existing grants council and planning to compare results.

In a DeSAi context, the stakes go beyond money to research direction and AI safety—areas where trust is paramount. A hybrid rollout allows the community to build that trust. Each successful futarchic decision (like a model update endorsed by the market that pans out in practice) boosts confidence. Each hiccup or exploit is an **opportunity to** **refine rules** (extending trading durations, adjusting incentives, etc.).

Overall, **moving step-by-step** from off-chain or minimal-stakes trials to fully on-chain futarchy is the recommended path. Start small, gather data, and scale up as the community gains experience and trust. By the time futarchy is fully deployed, participants will have the skills (like reading a prediction market), the infrastructure (oracles, UI, documentation), and the cultural acceptance to make it work. This **incremental approach** mirrors how AI models are typically trained—starting with safe scenarios and gradually deploying in the wild. Done carefully, the result is a governance system that’s both innovative and battle-tested.

---

## 6. Case Studies and Precedents

To ground this discussion, let’s examine a few case studies and precedents where futarchy or market-based governance models have been tested. These examples span fully decentralized prediction platforms to DAO governance experiments and provide insight into both the potential and pitfalls of futarchy in practice.

### **6-1. Augur – Decentralized Prediction Markets as Oracle Infrastructure**

_Augur_ is a decentralized prediction market platform on Ethereum, launched in 2018, which, while not a governance system itself, is directly relevant as one of the first implementations of crowd-based outcome betting. Augur allows users to create prediction markets on virtually any verifiable event – from elections to sports to crypto prices. Its significance to futarchy lies in its **oracle and incentive design**, which demonstrates how a decentralized network can ascertain truth and reward accuracy. Augur’s native token, **REP (Reputation)**, is used by a distributed set of reporters to **vote on the actual outcome of events** once markets expire. The rule is simple: REP holders are expected to report honestly on the outcome; if they don’t and are caught, they lose their tokens. In fact, Augur’s smart contracts are coded such that if a reporter submits an outcome that the majority (or the “truth”) disagrees with, that reporter’s staked REP is confiscated (slashed) and they forfeit any reporting fees. This creates a **strong economic incentive for honest reporting** – lying would cost real money. As a result, Augur has managed to function as a **decentralized oracle**, with the community of token holders collectively ensuring the correctness of market outcomes. This mechanism is essentially what a futarchy system’s oracle might mimic when verifying AI performance metrics. Augur also showed the power of crowd predictions: for instance, Augur markets during elections have often been as accurate as mainstream pollsters, vindicating the idea that a diverse crowd betting real money can out-predict individual experts. The platform did encounter issues – notably, low liquidity in many markets and some confusing user experience hurdles – which limited its widespread adoption. For example, initially there were instances of “dirty” markets (poorly worded or with ambiguous conditions) and low trading volume making prices volatile. However, from a governance perspective, Augur proved that **decentralized prediction markets can reach consensus on factual questions without centralized control**, and that the incentives can be aligned such that _truth-telling is the most profitable strategy_. This is a foundational requirement for futarchy. Augur’s experience also highlighted the importance of liquidity and user engagement: simply deploying the contracts wasn’t enough; efforts had to be made to attract traders and resolvers. Over time, Augur’s team iterated (even launching Augur v2) to improve market makers and validity bonds to weed out bad markets. For our purposes, Augur stands as a **proof-of-concept** that the “bet on beliefs” part works and that a community can serve as a decentralized arbiter of outcomes. Many later futarchy proposals (including Gnosis’s and others) cite Augur (and its precursor, the Truthcoin paper) as inspiration. In short, Augur was the _toolkit_ that made one piece of futarchy – the prediction market and oracle – a reality. A futarchy-based AI governance system could even piggyback on Augur or similar platforms for its markets and outcome resolutions.

### **6-2. GnosisDAO – Experimenting with Futarchic Governance**

_GnosisDAO_ was one of the earliest attempts to apply futarchy to the governance of a real organization (Gnosis, known for blockchain products like Gnosis Safe and a decentralized exchange). In November 2020, upon launching the DAO, Gnosis announced it would allocate part of its treasury to futarchy prediction markets and use their signals in decision-making. The process worked as follows: whenever a governance proposal was made (for example, _“Should Gnosis invest in launching product X?”_), two conditional markets would be created on the Gnosis conditional markets platform (a predecessor to the “Omen” prediction market). These markets were tied to the value of the Gnosis token (GNO) under each scenario: one market price represented the expected GNO price if the proposal passed, and the other if it failed. The rationale was that **GNO’s price can serve as a proxy metric for the success of the project** – if a proposal is good for Gnosis, traders would expect GNO to be more valuable in the future and bid it up in the “pass” market. The DAO supplemented these markets with significant liquidity from its own funds to encourage active trading (seeding 1,000 ETH and 20,000 GNO across markets). The outcome of the futarchy vote was then used to guide the actual governance vote. In GnosisDAO’s case, token holders still ultimately voted on-chain to ratify proposals, but they had the market data at hand as a guiding reference. This was a prudent step: it allowed observing whether the market and the vote diverged. In the proposals that followed, the **market predictions were often strongly one-sided** (e.g., indicating >95% confidence a proposal was beneficial), and indeed most token voters went along with the obvious choice. However, the experiment uncovered a few **challenges**:

#### _Speculative exploitation:_

Because there was both a market and a vote, and the vote outcome was in some cases nearly certain (token holders often signaled preferences on the forum), savvy speculators could exploit timing. As noted by an analyst, _“once a policy looked sure to pass, speculators could rush in and buy ‘YES’ tokens for a guaranteed payout.”_ ([Betting Billions On Predicting the Future (Gnosis Part I)](https://www.charterless.com/p/a-3b-bet-on-predicting-the-future#:~:text=given%20market%20to%20get%20reasonable,data)) Essentially, if voters (holding GNO) indicated they’d pass a proposal, the “pass” conditional market might not yet be at 100% – late traders could still buy and then when the vote passed, those tokens pay out at high value. This **distorted the market prices** (they became more a reflection of what voters signaled than independent information) and also meant Gnosis as the house was paying out these almost risk-free bets (since Gnosis funded liquidity, it effectively subsidized those winnings). In a pure futarchy (with no separate vote), this specific exploit wouldn’t occur, but the lesson was that **running markets in parallel with voting can create arbitrage loops**. The mitigation would be to either remove one or ensure the vote isn’t revealed until markets close (not practical in on-chain voting where votes are often public or predictable).

#### _Low participation and learning curve:_

Gnosis found that the prediction markets, while a novel idea, did not attract broad participation from their community beyond a small group of crypto-savvy traders. Most regular DAO members were content to vote as usual or even abstained, perhaps not fully understanding how to interact with the markets. This is a common challenge – futarchy introduces complexity (conditional tokens, understanding price implications) that can intimidate users. Without enough participants, the market can be dominated by a few players, reducing its wisdom-of-crowd benefit. GnosisDAO’s markets at times had such low liquidity that large trades moved prices sharply, which is not ideal for stable predictions.

#### _Outcome measurement:_

Gnosis used token price as the outcome (which is always measurable on-chain), avoiding oracle issues. But token price is an imperfect proxy; it can be influenced by broader market sentiment. So a proposal might be good, but if ETH crashes that week, GNO might drop regardless. This made it tricky to interpret short-term price moves. A refined approach could use longer-term or more specific metrics, but Gnosis chose token price for simplicity and immediacy. It highlighted that choosing the right metric for futarchy is crucial – it should closely tie to the decision’s impact.

Ultimately, after a few months, GnosisDAO quietly stepped back from futarchy. They did not continue creating new futarchy markets for every proposal (particularly after a merger with xDAI chain to form the Gnosis Chain, their governance shifted focus). The **experiment was considered unsuccessful in its initial form**, as the founder Martin Köppelmann admitted that significant redesign would be needed before it could work as intended. However, GnosisDAO’s bold trial was highly instructive. It demonstrated a working integration of on-chain governance with prediction markets (a **technical success** – the markets and contracts functioned as programmed), and it brought futarchy into practical discourse, surfacing real-world challenges. The takeaways influenced other projects: for example, recognizing the participation issue, later futarchy implementations like **Solana’s MetaDAO** put more emphasis on UX and incentives for traders; recognizing the manipulation issue, they use TWAP and removed parallel human voting. Gnosis also spawned Omen (now part of the DXdao) which continues to run prediction markets, and that tech is available for others. In sum, GnosisDAO can be viewed as the **first live futarchy governance pilot**, showing that while the idea is sound, the execution must account for human factors and edge cases. It underscores why a gradual rollout (as we described earlier) is valuable – diving in headfirst with large sums at stake can lead to unintended exploits. Despite its short run, GnosisDAO’s futarchy experiment is often cited as a courageous attempt that provided critical lessons for the community.

### **6-3. MetaDAO and Solana’s Futarchy at Scale**

_MetaDAO_ is a more recent initiative (2023-2024) that effectively productized futarchy for use by DAOs, primarily in the Solana ecosystem. If GnosisDAO was an early prototype, MetaDAO is like version 2.0 of futarchy governance, incorporating fixes and aiming for scale. MetaDAO created a platform where DAOs can conduct futarchy votes easily: it provides the smart contract infrastructure (conditional markets, TWAP oracles, execution logic) and a user interface. By late 2024, MetaDAO reported that it had **facilitated 62 futarchy-based decisions across nine DAOs** including itself. Three of the largest Solana-based DAOs – _Jito (a MEV-focused project), Marinade (a staking pool), and Sanctum_ – completed their first futarchy votes post-Solana’s 2024 elections. Notably, **Sanctum DAO committed fully to futarchy** by using MetaDAO as its primary governance mechanism, essentially running all proposals through futarchy markets and not traditional votes. This marks one of the first cases of a DAO functioning entirely under futarchy rules.

MetaDAO’s approach had several improvements informed by past experiences:

- They used **Solana’s high throughput** to their advantage, enabling frequent price updates and a snappy user experience for traders. This helps with liquidity as traders can arbitrage or respond quickly without prohibitive fees.
- They implemented the **TWAP oracle** as standard (discussed earlier) to finalize decisions, greatly mitigating last-minute manipulation.
- They focused on **education and outreach**. For example, MetaDAO’s team engaged with communities to explain how to participate in futarchy and even conducted _mock futarchy exercises_. They emphasized that participants don’t need to be expert traders; even buying a few tokens in the direction of their belief contributes to the decision.
- MetaDAO also built in **analytics and charts** to visualize the market as it runs, so DAO members can see the trend of opinion. For instance, one can see a chart of price vs time, which helps interpret if consensus grew or flipped during the discussion period.
- Each DAO on MetaDAO can configure certain parameters (like how long markets run, what threshold of TWAP difference constitutes approval). This flexibility allows experimentation between DAOs and tailoring to community preferences.

The results have been promising. According to an analysis by Galaxy Digital, while participation is still lower than typical token voting (futarchy “voters” per proposal were fewer, on the order of tens to low hundreds), those who did participate put economic weight behind their views, averaging about $219 of value per “vote action” (trade). They observed around 246 distinct “vote actions” per futarchy on average – which, though fewer than the hundreds of on-chain votes in big DeFi proposals, is meaningful given each action carries more informational content than a yes/no click. Also, as expected, **fewer but more informed participants** can still lead to good decisions. MetaDAO reported decisions such as token burns, treasury allocations, and parameter changes that were made via futarchy and generally aligned with the communities’ goals. One interesting case was a **token burn proposal**: even the MetaDAO founder disagreed with it personally, but the futarchy markets strongly signaled it was beneficial (likely expecting the token price to increase due to lower supply), and indeed the proposal passed and was executed, resulting in a token burn that the market had “approved”. This demonstrated the futarchy system working even against leadership’s intuition – arguably a sign of decentralized success.

MetaDAO’s scale-up also validated some theoretical benefits of futarchy:

- It allowed **simultaneous consideration of multiple options**. In one instance, MetaDAO used _combinatorial markets_ to decide between more than two alternatives (e.g., choosing between different fee structures) rather than a binary choice. Traditional voting would require sequential votes or a complex ranking vote, but markets can handle multiple outcomes via conditional tokens on each choice. This shows futarchy’s flexibility for nuanced decisions.
- It showcased **faster decision-making**. Some Solana DAOs found that they could arrive at decisions more quickly with markets that continuously incorporate information, versus long governance proposal periods with debates. Essentially, the market price _is_ the debate distilled to a number, and if it stabilizes early at, say, “90% likely this is good”, the DAO might execute sooner.
- It enforced accountability: in one case, a proposal champion had financially backed their idea in the market; when the outcome wasn’t as positive as predicted, that individual bore a loss. This kind of accountability is hard to assign in normal governance (where a proposer faces little direct consequence if a passed proposal fails), but futarchy naturally imposes it.

There are still challenges: MetaDAO’s data indicated that while the mechanism works, **broad participation remains an issue** – many token holders simply abstain from both trading and voting, perhaps due to apathy or lack of knowledge. To mitigate this, MetaDAO and similar projects are exploring **liquidity incentives or hybrid models**. Interestingly, MetaDAO’s success on Solana has renewed interest on Ethereum; there’s talk of bringing similar futarchy tooling to Ethereum-based DAOs, potentially enabling _apples-to-apples comparisons_ of futarchy vs traditional governance in the coming years.

For AI governance, MetaDAO’s case is encouraging. It suggests that with the right tooling and community preparation, a group of stakeholders can effectively govern via markets. Particularly, it validates technical aspects like TWAP oracles and automated execution. If a DAO can use futarchy to decide on a DeFi parameter or a token burn, there is reason to believe an AI-focused DAO could use it to decide on a model update or research direction, provided the success metric is clear. MetaDAO also underscores the need for **community adaptation**: they took an iterative approach, even launching a _Futarchy Launchpad_ to help new DAOs start with futarchy from day one with some safeguards. Their belief is that starting a community with futarchy (instead of switching an old community to it) might avoid the inertia and confusion that GnosisDAO faced, because members join knowing “this is how decisions are made here.” Indeed, a few brand-new DAOs are set to launch using futarchy as the default governance in 2025. We will see how they fare, but it’s a significant development towards mainstreaming the concept.

### **6-4. Academic and Community Pilots**

Outside of product-oriented cases, futarchy and similar concepts have been tested in academia and by communities in smaller experiments. While these might not be as high-profile as Augur or Gnosis, they provide insight into how futarchy might work in environments beyond blockchain.

#### _Prediction Markets for Policy – Iowa Electronic Markets (IEM):_

The IEM (run by University of Iowa) and other academic prediction markets have long shown that markets can predict outcomes like elections or economic indicators more accurately than polls. While not used to _make_ decisions, this provided evidence that crowds can be wise. In a sense, futarchy extends that idea: if markets predict better, why not let them decide? Scholars have proposed futarchy-like systems for university departmental decisions or even corporate strategy, but getting organizations to formally adopt it has been tough due to cultural resistance. However, these studies often reinforce futarchy’s premise that market predictions are well-calibrated and incorporate dispersed information effectively.

#### _“Decision markets” trials:_

There have been controlled experiments where participants were asked to use play money to decide an outcome. For example, in 2017 a group of researchers set up a decision market about a charity donation (market bets would decide which charity gets a pot of real money, based on which choice would lead to greater measured impact). The participants were given data and could trade on which charity’s intervention would yield higher results. The outcome generally matched what domain experts later found to be the better choice – indicating that even a small group, when incentivized properly, made a sound decision. These instances are like micro-futarchies and often document high engagement from participants, who report that it forced them to think harder about the decision (since money was on the line, even if not their own).

#### _Optimism’s Futarchy Grants Contest:_

Mentioned earlier, Optimism (an Ethereum collective) launched a pilot in 2025 for grant allocations. This is a **case study in hybrid futarchy**. They identified a metric (increase in network TVL by projects) and asked forecasters to predict which grant applicants would achieve more of that metric. Importantly, they opted to use **reputation-weighted play tokens** instead of real capital to encourage broad participation while limiting Sybils. This contest is ongoing, but it represents a learning-oriented approach. If it shows that the crowd predictions correlate strongly with actual outcomes (i.e., projects the market favored do better), Optimism might integrate futarchy into their real grant process. It’s a valuable precedent for AI governance because it parallels how one might run a _dry run futarchy_ on AI research proposals using play money and expert input before committing real funds. The outcome of Optimism’s experiment will yield data on participation rates and accuracy which can inform DeSAi communities.

#### _Effective Altruism (EA) community debates:_

An interesting non-crypto example: in EA forums, members have experimented with _prediction threads_ on controversial decisions (for instance, “Will policy X reduce global warming by 2030?”). People state probabilities and even bet small amounts peer-to-peer. This isn’t formal futarchy, but it shows communities trying to inject prediction logic into decision discussions. Some EA writers have even proposed _“Idea Futures”_ for governmental decisions to combat populism with evidence-based forecasting. These discussions often cite futarchy and debate its feasibility, contributing to wider understanding.

In summary, across these case studies we see a spectrum from **pure platforms (Augur)** to **real governance trials (GnosisDAO, MetaDAO)** to **controlled experiments (Optimism, academia)**. The general findings are:

1. **Markets can aggregate information well** – Augur’s oracle works, MetaDAO’s decisions seem reasonable and have community buy-in.
2. **User experience and education are crucial** – participants need to understand and trust the system; whenever that was lacking (as in Gnosis’s case for many token holders), futarchy underperformed.
3. **There are known solutions for technical risks** – e.g., TWAP for manipulation, and these have been validated in MetaDAO’s larger sample of decisions.
4. **Futarchy can complement human judgment** – even when not fully controlling decisions, its predictive insight is valuable (Optimism’s use, Gnosis’s initial advisory use). This suggests a path where even if an organization doesn’t go full futarchy, they might run prediction markets to inform debates. In AI development, one could always have an “AI improvement prediction market” running in parallel to the research process, which would be beneficial on its own by highlighting community expectations and concerns.

It’s also clear that futarchy is still in early days of adoption – only a handful of DAO decisions have used it relative to the vast number of traditional votes. That means each new case study (including any DeSAi implementation) will contribute significantly to collective knowledge. If a DeSAi AI governance instance is launched, it will likely become a reference point in futurist governance discussions. By learning from the cases above, such a project can avoid earlier pitfalls and leverage what worked: e.g., use robust oracle/TWAP designs (from MetaDAO’s playbook), start with a hybrid/test phase (as Optimism does), and ensure clear communication of the value proposition (Augur struggled partly because many couldn’t see the point of its complexity; an AI DAO must clearly show futarchy’s benefit to its mission).

---

## 7. Risks and Mitigations

| **Risk**                           | **Description**                                                     | **Mitigation**                                                                                             |
| ---------------------------------- | ------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| Manipulation Risk                  | Certain groups deliberately skew prices                             | TWAP, AMM slippage, deeper markets, monitoring/alerts, etc.                                                |
| Low Liquidity & Whale Domination   | A small number of large participants monopolize decisions           | Incentivize trading, encourage smaller bets, set appropriate parameters, distribute tokens                 |
| Speculative Volatility             | Market prices swing drastically on rumors or fluctuations           | Fixed-duration trading, use TWAP averages, introduce circuit breakers, etc.                                |
| Metric Selection Issues (Goodhart) | Manipulating the metric (e.g., overfitting just to inflate numbers) | Use multiple metrics, re-evaluate metrics periodically, measure long-term performance, apply human review  |
| Collusion & Sybil Attacks          | Groups collude to distort prices, or use fake accounts              | Economic incentives that discourage collusion, minimum participant thresholds, identity/reputation systems |
| Complexity & User Onboarding       | General users find prediction market systems hard to grasp          | Educational materials, user-friendly UI/UX, small-scale test tokens, robust reward design                  |

No governance system is without risks, and Futarchy is no exception. In fact, because it intertwines economic markets with decision-making, it introduces some unique challenges. Here we enumerate the key risks associated with applying futarchy to AI development and discuss potential mitigations for each. The goal is to acknowledge these vulnerabilities and show how a well-designed system can address them, ensuring a **safe and effective futarchic governance**.

In evaluating these risks, it’s worth noting that many of them are not unique to futarchy – traditional governance has its own issues (whales dominating votes, voter apathy, metric fixation by leaders, etc.). Futarchy addresses some of those (e.g., it inherently penalizes misinformation by costing liars money, whereas in voting liars might sway votes with no direct penalty). But futarchy introduces a financial dimension that must be managed ethically (to avoid plutocracy). Mitigations like quadratic mechanisms, or capping the influence of any single address, can ensure it’s not just wealth deciding but informed wealth – and ideally, that informed wealth is broadly distributed because many people become informed and invest accordingly.

Ultimately, a well-designed futarchy for AI governance will **align incentives such that the best way to win money is to help the AI succeed**. If any participant finds a strategy to profit that doesn’t coincide with genuine AI improvement, that’s a flaw to be fixed either by rule changes or metric adjustments. The goal is an incentive structure so tight that _manipulating decisions to be bad is synonymous with setting money on fire._ When speculation and truth-seeking are properly fused, the market becomes a powerful ally of governance, not an adversary. Many of the mitigations above – TWAP, multi-metrics, participation incentives – are aimed at achieving this alignment and robustness.

Finally, maintaining a _human element_ as a safety valve (especially early on) is wise. For example, the community might elect a small committee with the power to delay or review a futarchy decision if they unanimously believe it was manipulated or harmful. This is akin to a circuit breaker in corporate futarchy proposals. If used rarely, it won’t undermine market discipline, but it’s there for extreme cases (much like how DAOs keep multi-sig admins around for emergencies even when most governance is on-chain). Over time, as confidence in futarchy grows, such backstops may become unnecessary.

In summary, while futarchy entails risks like any system, **each risk can be mitigated through a combination of economic design, technical safeguards, and social governance measures**. Early experiments (like GnosisDAO’s hiccups) have illuminated these and led to improved designs (as MetaDAO’s success shows). By learning from those and being proactive in system design, a futarchy-governed AI project can minimize dangers and create a resilient, fair decision process. As one researcher put it, _“the merit of a proposal, as judged by the collective intelligence of the market, should inform decision-making”_ – and with the right guardrails, that collective intelligence can be harnessed without letting collective folly or malfeasance take hold.

---

## 8. **End-to-End Futarchy Flow: From Proposals to Verified AI Improvements**

In a futarchy-driven system for AI governance, the real value lies in how each step—from proposing an idea to verifying its impact—connects into one cohesive “feedback loop.” This end-to-end process ensures that every governance decision is measured by clear data, anchored by oracle mechanisms, and ultimately reflected in the AIʼs performance. Below is a conceptual flow of how proposals mature within futarchy and close the loop on continuous AI optimization:

First, a **proposal** emerges—typically from community members or developers—detailing a specific change aimed at enhancing an agreed-upon success metric. For AI, this might involve introducing a new training dataset, altering hyperparameters, or refining alignment rules. Crucially, the proposal must reference the **metric** it promises to improve, whether it be higher accuracy on a test set, lower latency, or more reliable safety compliance. This explicit link to a quantifiable metric is fundamental to futarchy: participants know exactly what theyʼre “betting on.”

Once the proposal is formalized, the **prediction market** is spun up. Two or more outcome tokens (for instance, “Implement” vs. “Do Not Implement”) begin trading, with prices indicating the communityʼs collective forecast of the metric under each scenario. If a new dataset is expected to increase the modelʼs accuracy from 85% to 90%, the “Implement” token will reflect that optimism. Conversely, if participants feel the proposed change lacks merit, the “Implement” token price would remain low relative to the baseline “Do Not Implement.” During this trading window, individuals stake tokens according to their knowledge, domain expertise, or experimental evidence. By setting real value behind their beliefs, they discipline the marketplace to filter out hype and reward genuine insight.

As trading progresses, **time-weighted average price** (TWAP) safeguards protect against last-minute manipulation. Rather than deciding the proposal on one closing price, the system looks at a rolling or cumulative price over the entire trading period. This approach ensures that transient spikes or attempted “whale” manipulations can’t unilaterally tilt the outcome. By the end of the trading phase, the proposal’s fate is clear: if the market consensus (TWAP) price for “Implement” significantly exceeds “Do Not Implement,” the proposal is **approved** and a **smart contract** can automatically queue the change. If the baseline is favored, the proposal fails.

Following approval, **implementation** moves off-chain or semi-automated. For an AI project, this often means running a new training procedure, modifying an inference pipeline, or rolling out a new system version. Because futarchy focuses on real-world success metrics, the next critical step is to **measure the actual outcome**. Decentralized oracles—whether a small consortium of reputable evaluators or a more automated check—gather data on the AI’s post-update performance. This data might reveal the updated model’s accuracy or throughput, using a recognized test suite that the community agreed upon in the proposal phase. Multiple parties can submit their findings, and the oracle logic (potentially via majority voting or cryptographic proofs) determines the final verified metric.

Upon **posting the metric on-chain**, the futarchy market **settles**. Participants who bet correctly on the outcome (e.g., those who believed accuracy would indeed improve) see their positions pay out. Incorrect predictors lose their stake proportionally. This settlement phase cements the “skin in the game” principle: those who contributed real insight or research—perhaps running trial experiments, dissecting the code, or analyzing data—are rewarded, while empty speculation or guesswork is penalized. By tying real value to accurate forecasting, the system motivates rigorous vetting of every proposal.

Finally, this **closing of the loop** unlocks ongoing iteration. If the model improved as predicted, the community might further refine the same approach or propose adjacent solutions. If the update underperformed, that insight drives new proposals or corrective actions, with participants now more attuned to the system’s intricacies. Over time, these sequential futarchy cycles act like evolutionary pressure, pushing AI development toward high-impact, verifiable upgrades. Each cycle reaffirms or updates the success metrics, ensuring that the AI’s objectives stay aligned with both technical performance and community values.

In short, this end-to-end futarchy process weaves together:

1. A **proposal** tied to a quantifiable metric,
2. A **prediction market** disciplined by TWAP,
3. **Implementation** and real-world **oracle reporting** of results,
4. **Market settlement** rewarding or penalizing participants,
5. And a **renewed baseline** for the next iteration.

All these steps operate in a transparent, on-chain manner, ensuring that improvements are driven by measured data rather than subjective impressions or purely centralized decisions. This structured flow—proposal → trading → implementation → oracle verification → settlement—serves as the backbone of futarchy-based AI governance, closing the feedback loop so that every model refinement stands on provable, economically validated benefits. By institutionalizing a rigorous, data-centric cycle, futarchy allows AI ecosystems to evolve swiftly yet responsibly, always tethered to the metrics the community collectively deems most critical.

---

## 9. Conclusion: Futarchy as a Transformative Model for AI Governance

Futarchy offers a dynamic and innovative framework for governing AI development within the Decentralized Science + AI (DeSAi) paradigm, grounding decision-making in data-driven insights and verifiable outcomes. By integrating prediction markets into the governance process, Futarchy empowers communities to "bet on beliefs," aligning incentives around measurable success metrics rather than speculation or hierarchical control. This structured, end-to-end process—proposal creation, market trading with safeguards like time-weighted average price (TWAP), implementation, and oracle-verified results—creates a continuous improvement cycle that rewards accurate predictions and filters out unproven ideas. As an expert in AI governance, I see this model as a powerful mechanism to harness collective intelligence, ensuring that AI systems evolve in ways that are both technically robust and aligned with human values.

### Key Strengths and Real-World Insights

The potential of Futarchy lies in its ability to transform AI governance into a transparent, accountable, and participatory process. Real-world experiments, such as those conducted by Augur, GnosisDAO, and MetaDAO, have showcased its promise while illuminating practical challenges. These pilots demonstrate that a well-implemented Futarchy can systematically direct resources toward the most effective proposals—be it a new training dataset, an updated model architecture, or a redefined success metric—by leveraging the predictive power of markets. However, they also highlight critical dependencies: sufficient market liquidity, effective user onboarding, and meticulously designed metrics to prevent gaming or overfitting. Hybrid rollouts offer a pragmatic solution, allowing communities to transition gradually through off-chain trials or advisory markets, building trust and competence before fully embracing on-chain autonomy.

### Addressing Challenges with Forward-Thinking Solutions

Futarchy’s success hinges on overcoming these hurdles, but the tools to do so are within reach. Technical safeguards like TWAP and resilient oracles mitigate risks of manipulation, ensuring that market outcomes reflect sustained consensus rather than fleeting distortions. Meanwhile, iterative refinement of metric design—balancing specificity with flexibility—can prevent perverse incentives and keep the system focused on genuine progress. As DeSAi communities experiment with these solutions, Futarchy’s adaptability will strengthen, making it a scalable governance model capable of handling the complexity and rapid evolution of AI development.

### A Vision for the Future

Looking ahead, Futarchy’s emphasis on quantifiable outcomes and community participation positions it as a cornerstone for responsible AI governance. As more DeSAi projects integrate Futarchy or its hybrid variants, we will gain deeper insights into how on-chain governance, oracles, and iterative validation intersect to create robust, transparent ecosystems. This trajectory points to a future where AI development is not dictated by top-down directives or untested hype, but steered by a collaborative, data-backed process that prioritizes human needs. By weaving prediction markets into the fabric of AI governance, Futarchy offers a path to systems that are not only technically advanced but also trustworthy, ethical, and inclusive.

### A Paradigm Shift in AI Governance

Futarchy represents a philosophical and practical shift toward democratizing AI development. Its rigorous validation mechanisms and alignment of incentives set a new standard for how we can collectively shape the future of AI. While challenges remain—ranging from user education to metric optimization—the model’s adaptability and focus on measurable results make it uniquely suited to a field as dynamic as AI. The journey forward will demand ongoing experimentation, but the rewards are profound: a governance framework that empowers stakeholders, fosters genuine innovation, and ensures AI evolves in partnership with the communities it serves.

In essence, Futarchy reimagines AI governance as a living, iterative process—one where every improvement is cemented in performance data and every decision reflects the wisdom of the crowd. By combining this approach with DeSAi’s ethos of open research and transparent feedback, we unlock a powerful blueprint for guiding AI responsibly and scalably into the future. The possibilities are vast, and with disciplined exploration, Futarchy can lead us toward an AI landscape that is as equitable as it is advanced.
